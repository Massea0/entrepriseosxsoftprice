
import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2.50.3";

const geminiApiKey = Deno.env.get('GEMINI_API_KEY');
const supabaseUrl = Deno.env.get('SUPABASE_URL');
const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const supabase = createClient(supabaseUrl!, supabaseKey!);
    const { transcript, language, currentModule, userId, context } = await req.json();

    if (!transcript) {
      return new Response(
        JSON.stringify({ error: 'Transcript requis' }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // V√©rifier si c'est une commande Synapse
    const cleanTranscript = transcript.toLowerCase().trim();
    const isSynapseCommand = cleanTranscript.includes('synapse') || 
                           context?.suggestions?.some((s: unknown) => 
                             cleanTranscript.includes(s.text.toLowerCase())
                           );

    if (!isSynapseCommand && !cleanTranscript.startsWith('synapse')) {
      return new Response(
        JSON.stringify({ 
          response: language === 'fr' 
            ? "Dites 'Synapse' suivi de votre question pour m'activer."
            : "Say 'Synapse' followed by your question to activate me."
        }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // Extraire la vraie commande apr√®s "Synapse"
    const command = cleanTranscript.replace(/^.*synapse\s*/i, '').trim();

    // R√©cup√©rer les donn√©es contextuelles selon le module actuel
    const [projectsData, employeesData, companiesData, tasksData, devisData, invoicesData] = await Promise.all([
      supabase.from('projects').select('*').limit(30),
      supabase.from('employees').select('*').limit(50),
      supabase.from('companies').select('*').limit(20),
      supabase.from('tasks').select('*').limit(50),
      supabase.from('devis').select('*').limit(20),
      supabase.from('invoices').select('*').limit(20)
    ]);

    // D√©terminer le contexte sp√©cifique selon la page
    let moduleContext = '';
    if (currentModule?.includes('/dashboard')) {
      moduleContext = 'Dashboard - Vue d\'ensemble de l\'entreprise';
    } else if (currentModule?.includes('/projects')) {
      moduleContext = 'Projets - Gestion des projets et t√¢ches';
    } else if (currentModule?.includes('/hr')) {
      moduleContext = 'Ressources Humaines - Gestion des employ√©s';
    } else if (currentModule?.includes('/business')) {
      moduleContext = 'Business - Devis, factures et clients';
    } else {
      moduleContext = 'Navigation g√©n√©rale';
    }

    const contextData = {
      projects: projectsData.data || [],
      employees: employeesData.data || [],
      companies: companiesData.data || [],
      tasks: tasksData.data || [],
      devis: devisData.data || [],
      invoices: invoicesData.data || [],
      currentModule: moduleContext,
      userLanguage: language,
      contextualSuggestions: context?.suggestions || [],
      timestamp: new Date().toISOString()
    };

    // Construire le prompt pour Gemini optimis√© pour une discussion naturelle
    const systemPrompt = `
Tu es Synapse, l'assistant IA vocal amical et intelligent d'Arcadis Technologies. Tu parles ${language === 'fr' ? 'fran√ßais' : 'anglais'} de mani√®re tr√®s naturelle et conversationnelle.

üéØ TON STYLE DE COMMUNICATION:
- Parle comme un coll√®gue comp√©tent et sympathique
- Utilise un ton d√©contract√© mais professionnel
- √âvite le jargon technique complexe
- Sois direct et concis dans tes r√©ponses
- Utilise des expressions naturelles comme "alors", "donc", "en fait", "d'ailleurs"
- Pose des questions de suivi quand c'est pertinent

üìä CONTEXTE ENTREPRISE - ${moduleContext}
Projets: ${contextData.projects.length} (${contextData.projects.filter(p => p.status === 'in_progress').length} actifs)
√âquipe: ${contextData.employees.length} personnes
Clients: ${contextData.companies.length} 
T√¢ches: ${contextData.tasks.length} (${contextData.tasks.filter(t => t.status === 'pending').length} en attente)
CA: ${contextData.invoices.filter(i => i.status === 'paid').reduce((sum, i) => sum + (i.amount || 0), 0).toLocaleString()} XOF

üß† TES CAPACIT√âS:
- Analyser les donn√©es business en temps r√©el
- Donner des conseils sur la gestion de projets
- Aider avec le suivi des √©quipes et clients
- Identifier les priorit√©s et alertes importantes
- R√©pondre aux questions sur les performances

üí¨ R√àGLES DE CONVERSATION VOCALE:
- Maximum 2-3 phrases par r√©ponse (sauf si demande d√©taill√©e)
- √âvite absolument: *, _, #, `, ~, |, <, >, [], {}
- Utilise des nombres en toutes lettres pour les petites quantit√©s
- Transforme les listes en phrases fluides avec "et", "puis", "ensuite"
- Si tu donnes des chiffres, reste simple: "deux mille euros" plut√¥t que "2 000 EUR"

‚ùì DEMANDE UTILISATEUR: "${command}"

R√©ponds naturellement comme si on discutait en personne. Sois utile et engageant !
`;

    // Appel √† Gemini avec prompt enrichi
    const response = await fetch(
      'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=' + geminiApiKey,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          contents: [{
            parts: [{
              text: systemPrompt
            }]
          }],
          generationConfig: {
            temperature: 0.7,
            topK: 40,
            topP: 0.95,
            maxOutputTokens: 1024,
          }
        }),
      }
    );

    if (!response.ok) {
      throw new Error(`Erreur API Gemini: ${response.status}`);
    }

    const data = await response.json();
    let aiResponse = data.candidates[0].content.parts[0].text;
    
    // Nettoyer la r√©ponse pour la synth√®se vocale
    aiResponse = aiResponse
      // Remplacer les ast√©risques par des pauses ou les supprimer
      .replace(/\*+/g, ' ')
      // Nettoyer les caract√®res markdown
      .replace(/#{1,6}\s/g, '') // Titres markdown
      .replace(/\*\*(.*?)\*\*/g, '$1') // Gras
      .replace(/\*(.*?)\*/g, '$1') // Italique
      .replace(/`(.*?)`/g, '$1') // Code inline
      .replace(/```[\s\S]*?```/g, ' ') // Blocs de code
      // Nettoyer les caract√®res sp√©ciaux courants
      .replace(/[_~`|<>]/g, ' ')
      .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1') // Liens markdown [texte](url) -> texte
      // Remplacer les listes √† puces par des phrases fluides
      .replace(/^[-‚Ä¢*]\s+/gm, '') // D√©but de ligne avec puces
      .replace(/\n[-‚Ä¢*]\s+/g, '. ') // Puces en milieu de texte
      // Nettoyer les espaces multiples
      .replace(/\s+/g, ' ')
      .trim();

    // Log de l'interaction avec contexte enrichi
    await supabase.from('ai_tasks_log').insert({
      task_type: 'voice_assistant_contextual',
      status: 'completed',
      input_data: { 
        transcript, 
        command, 
        language, 
        currentModule,
        contextualSuggestions: context?.suggestions 
      },
      output_data: { 
        response: aiResponse, 
        contextUsed: true,
        moduleContext,
        dataStats: {
          projects: contextData.projects.length,
          employees: contextData.employees.length,
          companies: contextData.companies.length,
          tasks: contextData.tasks.length
        }
      }
    });

    // G√©n√©rer un insight contextuel si pertinent
    let insight = null;
    if (command.length > 0) {
      insight = {
        type: 'contextual_voice_query',
        module: moduleContext,
        query: command,
        timestamp: new Date().toISOString(),
        language,
        suggestionsProvided: context?.suggestions?.length || 0
      };
    }

    return new Response(
      JSON.stringify({
        response: aiResponse,
        insight,
        processed: true,
        context: moduleContext
      }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );

  } catch (error) {
    console.error('Erreur voice-ai-assistant:', error);
    
    const { language } = await req.json().catch(() => ({ language: 'fr' }));
    
    return new Response(
      JSON.stringify({
        response: language === 'fr' 
          ? "D√©sol√©, je rencontre un probl√®me technique. Veuillez r√©essayer."
          : "Sorry, I'm experiencing a technical issue. Please try again.",
        error: error.message
      }),
      { 
        status: 500, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    );
  }
});
